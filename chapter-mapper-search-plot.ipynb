{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZZsdemrx7ASPvlevObmFAg_I3D3zYMgi","timestamp":1675030225489}],"authorship_tag":"ABX9TyOZBe9k0XcC6uWKm73/AenN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#@title Overview\n","\n","#@markdown The main purpose of this code is to allow users to query a large body of text relevant to their project easily. It also includes a functionality to visualize the text data in 2 dimensions, which is useful for drawing connections and relatedness between different text chunks."],"metadata":{"cellView":"form","id":"z30HPbrL9fG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"v9cDAz5j2SqT"},"outputs":[],"source":["#@title User-Defined Variables\n","search_query = \"\" #@param\n","chapter_mapper_folder = \"/content/drive/MyDrive/chapter-mapper\" #@param\n","pdf_folder = \"Insert relative folder pathname here containing PDF's you want to search #@param\n","chunk_size = 128 #@param\n","chunk_overlap = 0.1 #@param\n","number_results = 3 #@param\n","openai_api_key = \"Insert your OpenAI API Key here\" #@param\n","save_name_suffix = \"[with-embeddings].csv\" #@param\n","COMPLETIONS_MODEL = \"text-davinci-003\" #@param\n","EMBEDDING_MODEL = \"text-embedding-ada-002\"#@param\n","\n","#@markdown ---\n","#@markdown ### **Help**\n","#@markdown - **`search_query`** - *`str; The question or information you would like to search for that is related to the text contained in pdf_folder.`*\n","#@markdown - **`chapter_mapper_folder`** - *`str; The name of the chapter-mapper root folder.`*\n","#@markdown - **`pdf_folder`** - *`str; The name of the folder which contains all the PDF's you want to analyze.`*\n","#@markdown - **`chunk_size`** - *`int; How many words you want each chunk of text to contain (approximately). Default is 256.`*\n","#@markdown - **`chunk_overlap`** - *`float; How much overlap you want each chunk of text to have with the next chunk. Default is 0.1.`*\n","#@markdown - **`number_results`** - *`int; How many search results you want to see in the plot. Default is 10.`*\n","#@markdown - **`openai_api_key`** - *`str; Your (free trial) OpenAI API Key`*\n","#@markdown - **`save_name_suffix`** - *`str; string to add to end of csv file for saving purposes. Default is '[with-embeddings].csv'`*\n","#@markdown - **`COMPLETIONS_MODEL`** - *`str; The name of the model to use for answering prompts. Default is 'text-davinci-003' from OpenAI.`*\n","#@markdown - **`EMBEDDING_MODEL`** - *`str; The name of the model to use for obtaining text embeddings. Default is 'text-embedding-ada-002' from OpenAI.`*"]},{"cell_type":"code","source":["#@title Mount Drive\n","from google.colab import drive, files\n","from IPython.display import HTML\n","import os\n","import sys\n","import shutil\n","import subprocess\n","output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","default_packages = output.stdout.decode().strip().split(\"\\n\")\n","drive.mount('/content/drive')\n","!mkdir /content/drive/MyDrive/python-packages\n","%cd '/content/drive/MyDrive/python-packages'\n","sys.path.append('/content/drive/MyDrive/python-packages')"],"metadata":{"cellView":"form","id":"sNJgsZcX9_6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Install Required Packages\n","try:\n","  import openai\n","except:\n","  subprocess.run([\"pip\",\"install\",\"openai\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",f\"--target=/content/drive/MyDrive/python-packages\"])\n","  import openai\n","try:\n","  import fitz\n","except:\n","  subprocess.run([\"pip\",\"install\",\"pymupdf\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",f\"--target=/content/drive/MyDrive/python-packages\"])\n","  import fitz\n","try:\n","  import tiktoken\n","except:\n","  subprocess.run([\"pip\",\"install\",\"tiktoken\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list1 = list(set(default_packages) - set(new_packages))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list1 + non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",\"--target=/content/drive/MyDrive/python-packages\"])\n","  import tiktoken\n","subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))"],"metadata":{"id":"tF7uhZo6zIiu","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Change Working Directory to `chapter_mapper_folder`\n","%cd {chapter_mapper_folder}"],"metadata":{"cellView":"form","id":"5BEgkWpD66vl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Import Dependencies\n","import numpy as np\n","import colorsys\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import textwrap\n","import os\n","from utils import batch_embed, ChapterExtractor\n","from matplotlib import colors as mcolors\n","from sklearn.manifold import TSNE\n","from openai.embeddings_utils import get_embedding, cosine_similarity\n","from typing import List, Dict, Tuple\n","from tqdm import tqdm\n","import pickle\n","openai.api_key = openai_api_key"],"metadata":{"cellView":"form","id":"Fq8ZtiHx534x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Collect Data from all PDF's in `pdf_folder`\n","df_init = pd.DataFrame()\n","pdfs = np.unique([os.path.join(pdf_folder,x) for x in os.listdir(pdf_folder) if '.pdf' in x]).tolist()\n","cs = int(chunk_size)\n","file_prefix = pdf_folder + f'-cs={cs}-co={chunk_overlap:.2f}-raw-data' \n","if not os.path.exists(f'{pdf_folder}/{file_prefix}.csv'):\n","  for pdf in pdfs:\n","    print(len(df_init))\n","    df_temp = ChapterExtractor(pdf,chunk_size,chunk_overlap).get_df()\n","    df_init = pd.concat([df_init,df_temp])\n","  df_init.to_csv(f'{pdf_folder}/{file_prefix}.csv',encoding='utf-8-sig')\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}.csv')\n","else:\n","  print(f'Loading raw data from {pdf_folder}/{file_prefix}.csv...')\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}.csv')"],"metadata":{"id":"Wqwwj5D7_Ig3","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Create Embeddings for the Raw Data\n","if not os.path.exists(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv'):\n","  batch_embed(df_init,200,'chunk_text') # adds embedding column to the textbook data file\n","  df_init.to_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv',encoding='utf-8-sig')\n","else:\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv')"],"metadata":{"cellView":"form","id":"xZl-Rtb7o3a2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Obtain TSNE Matrix Data for 2D Map Visualization\n","df = df_init\n","def feature_matrix(df):\n","    print(\"Extracting Embedding Feature Matrix...\")\n","    matrix = df.embeddings.to_list()\n","    matrix_empty = np.zeros((len(matrix), len(matrix[0])))\n","    for i in range(len(matrix)):\n","        try:\n","            matrix_empty[i, :] = np.array(matrix[i])\n","        except Exception as e:\n","            print(i, e)\n","            print(matrix[i])\n","            exit()\n","    matrix = matrix_empty\n","    return matrix\n","\n","def toarray(x):\n","    if isinstance(x, str):\n","        x = [float(v.strip()) for v in x.strip('[').strip(']').split(',')]\n","    return x\n","    \n","def search_text(df, search_query, n):\n","    embedding = get_embedding(\n","        search_query,\n","        engine=EMBEDDING_MODEL\n","    )\n","    df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(np.asarray(toarray(x), dtype='float64'), np.asarray(embedding, dtype='float64')))\n","    results = list(df.sort_values(\"similarity\", ascending=False).head(n).description)\n","    return results\n","\n","css4_colors = mcolors.CSS4_COLORS\n","\n","def get_hsv(color_name):\n","    hexrgb = css4_colors[color_name]\n","    hexrgb = hexrgb.lstrip(\"#\")   # in case you have Web color specs\n","    r, g, b = (int(hexrgb[i:i+2], 16) / 255.0 for i in range(0,5,2))\n","    return colorsys.rgb_to_hsv(r, g, b)\n","\n","def filter_search(df, search_results):\n","    df['keep'] = [x in search_results for x in list(df.description)]\n","    df = df[df['keep'] == True].filter(list(df.columns)[:-1])\n","    print(df.shape)\n","    return df\n","\n","all_titles = list(df.title.unique())\n","colors = list(css4_colors.keys())\n","colors = np.random.choice(colors, len(all_titles), False)\n","colors = sorted(colors, key=get_hsv)\n","df['color'] = [css4_colors[colors[all_titles.index(i)]] for i in list(df.title)]\n","dm = {all_titles[i]: colors[i] for i in range(len(all_titles))}\n","\n","if not os.path.exists(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv'):\n","  df['embedding-new'] = df.embeddings.apply(np.array)\n","  print(\"Evaluating TSNE on Dataset...\")\n","  tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n","  matrix = feature_matrix(df)\n","  vis_dims = tsne.fit_transform(matrix)\n","  df['x'] = [x for x,y in vis_dims]\n","  df['y'] = [y for x,y in vis_dims]\n","  df['description']  = [\"<br>\".join(textwrap.wrap(d)) for d in list(df.chunk_text)]\n","  df.to_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv')\n","else:\n","  df = pd.read_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv')\n","  df['description']  = [\"<br>\".join(textwrap.wrap(d)) for d in list(df.chunk_text)]"],"metadata":{"cellView":"form","id":"0dmMxQEyzzU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Plot Results and Answer Question based on Text Data\n","if len(search_query) == 0:\n","  fig = px.scatter(df, x='x', y='y', color='title', hover_data=['title', 'chapter', 'page', 'description'], color_discrete_map=dm, category_orders={'title': all_titles}, template=\"plotly_dark\", title=f\"{pdf_folder} Visualized\")\n","  fig.show()\n","else:\n","  print(\"Searching for relevant text...\")\n","  search_results = list(search_text(df, search_query, number_results))\n","  # print(search_results)\n","  df_filter = filter_search(df, search_results)\n","  fig = px.scatter(df_filter, x='x', y='y', color='title', hover_data=['title', 'similarity', 'chapter', 'page', 'description'], color_discrete_map=dm, category_orders={'title': all_titles}, template=\"plotly_dark\", title=f\"Text in {pdf_folder} related to '{search_query}'\")\n","  fig.update_layout(hoverlabel=dict(font=dict(family='Arial', size=12, color='black'),align='left'))\n","  fig.show()\n","\n","MAX_SECTION_LEN = 1500\n","SEPARATOR = \"\\n* \"\n","ENCODING = \"cl100k_base\"  # encoding for text-embedding-ada-002\n","\n","encoding = tiktoken.get_encoding(ENCODING)\n","separator_len = len(encoding.encode(SEPARATOR))\n","\n","f\"Context separator contains {separator_len} tokens\"\n","\n","def vector_similarity(x: List[float], y: List[float]) -> float:\n","    \"\"\"\n","    Returns the similarity between two vectors.\n","    \n","    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n","    \"\"\"\n","    return np.dot(np.array(x), np.array(y))\n","\n","def order_document_sections_by_query_similarity(query: str, df:pd.DataFrame) -> List[Tuple[float, Tuple[str, str]]]:\n","    \"\"\"\n","    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n","    to find the most relevant sections. \n","    \n","    Return the list of document sections, sorted by relevance in descending order.\n","    \"\"\"\n","    query_embedding = get_embedding(query,engine=EMBEDDING_MODEL)\n","    if isinstance(df.embeddings[0],str):\n","      contexts = df.embeddings.apply(eval)\n","    else:\n","      contexts = df.embeddings\n","    \n","    document_similarities = sorted([\n","        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n","    ], reverse=True)\n","    \n","    return document_similarities\n","\n","def construct_prompt(question: str, df: pd.DataFrame) -> str:\n","    \"\"\"\n","    Fetch relevant \n","    \"\"\"\n","    most_relevant_document_sections = order_document_sections_by_query_similarity(question, df)\n","    \n","    chosen_sections = []\n","    chosen_sections_len = 0\n","    chosen_sections_indexes = []\n","     \n","    for _, section_index in most_relevant_document_sections:\n","        # Add contexts until we run out of space.        \n","        document_section = df.loc[section_index]\n","        \n","        chosen_sections_len += document_section.tokens + separator_len\n","        if chosen_sections_len > MAX_SECTION_LEN:\n","            break\n","            \n","        chosen_sections.append(SEPARATOR + document_section.chunk_text.replace(\"\\n\", \" \"))\n","        chosen_sections_indexes.append(str(section_index))\n","            \n","    # Useful diagnostic information\n","    print(f\"Selected {len(chosen_sections)} document sections:\")\n","    print(\"\\n\".join(chosen_sections_indexes))\n","    \n","    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know, but here is what I found:\"\\n\\nContext:\\n\"\"\"\n","    \n","    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\"\n","\n","COMPLETIONS_API_PARAMS = {\n","    # We use temperature of 0.1 because it gives the most predictable, factual answer.\n","    \"temperature\": 0.1,\n","    \"max_tokens\": 1000,\n","    \"model\": COMPLETIONS_MODEL,\n","}\n","\n","def answer_query_with_context(\n","    query: str,\n","    df: pd.DataFrame,\n","    show_prompt: bool = False\n",") -> str:\n","    prompt = construct_prompt(\n","        query,\n","        df\n","    )\n","    \n","    if show_prompt:\n","        print(prompt)\n","\n","    response = openai.Completion.create(\n","                prompt=prompt,\n","                **COMPLETIONS_API_PARAMS\n","            )\n","\n","    return response[\"choices\"][0][\"text\"].strip(\" \\n\")\n","\n","if len(search_query) > 0:\n","  print(answer_query_with_context(search_query, df))"],"metadata":{"cellView":"form","id":"4eckMR244tif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Save the Plot as an HTML File\n","file_out = f\"{pdf_folder}-{search_query}\"\n","go.Figure.write_html(fig,f\"{file_out}.html\") # write as html or image\n","files.download(f\"{file_out}.html\") # download your file and give me a vote my answer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"cellView":"form","id":"zl5Rpgww7WMN","executionInfo":{"status":"ok","timestamp":1675027376500,"user_tz":300,"elapsed":158,"user":{"displayName":"Malek Ibrahim","userId":"14928610410385521342"}},"outputId":"da15ca17-a688-4f18-867b-24ffc68b19c5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6f5d2255-a393-456d-a5b7-2936575d153e\", \"labview-What is the purpose of queueing in LabVIEW?.html\", 3688340)"]},"metadata":{}}]}]}