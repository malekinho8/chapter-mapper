{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZZsdemrx7ASPvlevObmFAg_I3D3zYMgi","timestamp":1675034898081}],"authorship_tag":"ABX9TyOl3ZSQnN9T0x34B/LLE0IA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#@title Overview\n","\n","#@markdown The main purpose of this code is to allow users to query a large body of text relevant to their project easily. In the future, a visualization tool may also be combined to allow users to visualize their knowledge space in two dimensions and reveal potential connections and such."],"metadata":{"cellView":"form","id":"z30HPbrL9fG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"v9cDAz5j2SqT","executionInfo":{"status":"ok","timestamp":1675259266135,"user_tz":360,"elapsed":3,"user":{"displayName":"Malek Ibrahim","userId":"14928610410385521342"}}},"outputs":[],"source":["#@title User-Defined Variables\n","search_query = \"Insert question here!\" #@param\n","chapter_mapper_folder = \"/content/drive/MyDrive/chapter-mapper\" #@param\n","pdf_folder = \"Insert name of folder containing relevant PDFs\" #@param\n","chunk_size = 256 #@param\n","chunk_overlap = 0.1 #@param\n","number_results = 3 #@param\n","openai_api_key = \"Insert OpenAI API Key here\" #@param\n","save_name_suffix = \"[with-embeddings]\" #@param\n","COMPLETIONS_MODEL = \"text-davinci-003\" #@param\n","EMBEDDING_MODEL = \"text-embedding-ada-002\"#@param\n","\n","#@markdown ---\n","#@markdown ### **Help**\n","#@markdown - **`search_query`** - *`str; The question or information you would like to search for that is related to the text contained in pdf_folder.`*\n","#@markdown - **`chapter_mapper_folder`** - *`str; The name of the chapter-mapper root folder.`*\n","#@markdown - **`pdf_folder`** - *`str; The name of the folder which contains all the PDF's you want to analyze.`*\n","#@markdown - **`chunk_size`** - *`int; How many words you want each chunk of text to contain (approximately). Default is 256.`*\n","#@markdown - **`chunk_overlap`** - *`float; How much overlap you want each chunk of text to have with the next chunk. Default is 0.1.`*\n","#@markdown - **`number_results`** - *`int; How many search results you want to see in the plot. Default is 10.`*\n","#@markdown - **`openai_api_key`** - *`str; Your (free trial) OpenAI API Key`*\n","#@markdown - **`save_name_suffix`** - *`str; string to add to end of csv file for saving purposes. Default is '[with-embeddings].csv'`*\n","#@markdown - **`COMPLETIONS_MODEL`** - *`str; The name of the model to use for answering prompts. Default is 'text-davinci-003' from OpenAI.`*\n","#@markdown - **`EMBEDDING_MODEL`** - *`str; The name of the model to use for obtaining text embeddings. Default is 'text-embedding-ada-002' from OpenAI.`*"]},{"cell_type":"code","source":["#@title Mount Drive\n","from google.colab import drive, files\n","from IPython.display import HTML\n","import os\n","import sys\n","import shutil\n","import subprocess\n","output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","default_packages = output.stdout.decode().strip().split(\"\\n\")\n","drive.mount('/content/drive')\n","!mkdir /content/drive/MyDrive/python-packages\n","%cd '/content/drive/MyDrive/python-packages'\n","sys.path.append('/content/drive/MyDrive/python-packages')"],"metadata":{"cellView":"form","id":"sNJgsZcX9_6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Install Required Packages\n","try:\n","  import openai\n","except:\n","  subprocess.run([\"pip\",\"install\",\"openai\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",f\"--target=/content/drive/MyDrive/python-packages\"])\n","  import openai\n","try:\n","  import fitz\n","except:\n","  subprocess.run([\"pip\",\"install\",\"pymupdf\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",f\"--target=/content/drive/MyDrive/python-packages\"])\n","  import fitz\n","try:\n","  import tiktoken\n","except:\n","  subprocess.run([\"pip\",\"install\",\"tiktoken\"])\n","  output = subprocess.run([\"pip\", \"list\"], capture_output=True)\n","  new_packages = output.stdout.decode().strip().split(\"\\n\")\n","  subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))\n","  non_common_elements_list1 = list(set(default_packages) - set(new_packages))\n","  non_common_elements_list2 = list(set(new_packages) - set(default_packages))\n","  non_common_elements = non_common_elements_list1 + non_common_elements_list2\n","  for element in non_common_elements:\n","    element = element.split()[0]+\"==\"+element.split()[1]\n","    subprocess.run([\"pip\", \"install\",element,\"--no-deps\",\"--target=/content/drive/MyDrive/python-packages\"])\n","  import tiktoken\n","subprocess.run(['pip', 'freeze'], stdout=open(f\"{chapter_mapper_folder}/requirements.txt\", 'w'))"],"metadata":{"id":"tF7uhZo6zIiu","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Change Working Directory to `chapter_mapper_folder`\n","%cd {chapter_mapper_folder}"],"metadata":{"cellView":"form","id":"5BEgkWpD66vl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Import Dependencies\n","import numpy as np\n","import colorsys\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import textwrap\n","import os\n","from utils import batch_embed, ChapterExtractor, answer_query_with_context\n","from matplotlib import colors as mcolors\n","from sklearn.manifold import TSNE\n","from openai.embeddings_utils import get_embedding, cosine_similarity\n","from typing import List, Dict, Tuple\n","from tqdm import tqdm\n","import pickle\n","openai.api_key = openai_api_key"],"metadata":{"cellView":"form","id":"Fq8ZtiHx534x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Collect Data from all PDF's in `pdf_folder`\n","df_init = pd.DataFrame()\n","pdfs = np.unique([os.path.join(pdf_folder,x) for x in os.listdir(pdf_folder) if '.pdf' in x]).tolist()\n","cs = int(chunk_size)\n","file_prefix = pdf_folder + f'-cs={cs}-co={chunk_overlap:.2f}-raw-data' \n","if not os.path.exists(f'{pdf_folder}/{file_prefix}.csv'):\n","  for pdf in pdfs:\n","    print(len(df_init))\n","    df_temp = ChapterExtractor(pdf,chunk_size,chunk_overlap).get_df()\n","    df_init = pd.concat([df_init,df_temp])\n","  df_init.to_csv(f'{pdf_folder}/{file_prefix}.csv',encoding='utf-8-sig')\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}.csv')\n","else:\n","  print(f'Loading raw data from {pdf_folder}/{file_prefix}.csv...')\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}.csv')"],"metadata":{"id":"Wqwwj5D7_Ig3","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Create Embeddings for the Raw Data\n","if not os.path.exists(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv'):\n","  batch_embed(df_init,200,'chunk_text') # adds embedding column to the textbook data file\n","  df_init.to_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv',encoding='utf-8-sig')\n","else:\n","  df_init = pd.read_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}.csv')"],"metadata":{"cellView":"form","id":"xZl-Rtb7o3a2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Obtain TSNE Matrix Data for 2D Map Visualization\n","df = df_init\n","def feature_matrix(df):\n","    print(\"Extracting Embedding Feature Matrix...\")\n","    matrix = df.embeddings.to_list()\n","    matrix_empty = np.zeros((len(matrix), len(matrix[0])))\n","    for i in range(len(matrix)):\n","        try:\n","            matrix_empty[i, :] = np.array(matrix[i])\n","        except Exception as e:\n","            print(i, e)\n","            print(matrix[i])\n","            exit()\n","    matrix = matrix_empty\n","    return matrix\n","\n","def toarray(x):\n","    if isinstance(x, str):\n","        x = [float(v.strip()) for v in x.strip('[').strip(']').split(',')]\n","    return x\n","    \n","def search_text(df, search_query, n):\n","    embedding = get_embedding(\n","        search_query,\n","        engine=EMBEDDING_MODEL\n","    )\n","    df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(np.asarray(toarray(x), dtype='float64'), np.asarray(embedding, dtype='float64')))\n","    results = list(df.sort_values(\"similarity\", ascending=False).head(n).description)\n","    return results\n","\n","css4_colors = mcolors.CSS4_COLORS\n","\n","def get_hsv(color_name):\n","    hexrgb = css4_colors[color_name]\n","    hexrgb = hexrgb.lstrip(\"#\")   # in case you have Web color specs\n","    r, g, b = (int(hexrgb[i:i+2], 16) / 255.0 for i in range(0,5,2))\n","    return colorsys.rgb_to_hsv(r, g, b)\n","\n","def filter_search(df, search_results):\n","    df['keep'] = [x in search_results for x in list(df.description)]\n","    df = df[df['keep'] == True].filter(list(df.columns)[:-1])\n","    print(df.shape)\n","    return df\n","\n","all_titles = list(df.title.unique())\n","colors = list(css4_colors.keys())\n","colors = np.random.choice(colors, len(all_titles), False)\n","colors = sorted(colors, key=get_hsv)\n","df['color'] = [css4_colors[colors[all_titles.index(i)]] for i in list(df.title)]\n","dm = {all_titles[i]: colors[i] for i in range(len(all_titles))}\n","\n","if not os.path.exists(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv'):\n","  df['embedding-new'] = df.embeddings.apply(np.array)\n","  print(\"Evaluating TSNE on Dataset...\")\n","  tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n","  matrix = feature_matrix(df)\n","  vis_dims = tsne.fit_transform(matrix)\n","  df['x'] = [x for x,y in vis_dims]\n","  df['y'] = [y for x,y in vis_dims]\n","  df['description']  = [\"<br>\".join(textwrap.wrap(d)) for d in list(df.chunk_text)]\n","  df.to_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv')\n","else:\n","  df = pd.read_csv(f'{pdf_folder}/{file_prefix}-{save_name_suffix}-[with-TSNE].csv')\n","  df['description']  = [\"<br>\".join(textwrap.wrap(d)) for d in list(df.chunk_text)]"],"metadata":{"cellView":"form","id":"0dmMxQEyzzU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Plot Results and Answer Question based on Text Data\n","if len(search_query) == 0:\n","  fig = px.scatter(df, x='x', y='y', color='title', hover_data=['title', 'chapter', 'page', 'description'], color_discrete_map=dm, category_orders={'title': all_titles}, template=\"plotly_dark\", title=f\"{pdf_folder} Visualized\")\n","  fig.show()\n","else:\n","  print(\"Searching for relevant text...\")\n","  search_results = list(search_text(df, search_query, number_results))\n","  # print(search_results)\n","  df_filter = filter_search(df, search_results)\n","  fig = px.scatter(df_filter, x='x', y='y', color='title', hover_data=['title', 'similarity', 'chapter', 'page', 'description'], color_discrete_map=dm, category_orders={'title': all_titles}, template=\"plotly_dark\", title=f\"Text in {pdf_folder} related to '{search_query}'\")\n","  fig.update_layout(hoverlabel=dict(font=dict(family='Arial', size=12, color='black'),align='left'))\n","  fig.show()\n","\n","if len(search_query) > 0:\n","  print(answer_query_with_context(search_query, df, COMPLETIONS_MODEL=COMPLETIONS_MODEL, EMBEDDING_MODEL=EMBEDDING_MODEL))"],"metadata":{"cellView":"form","id":"4eckMR244tif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Save the Plot as an HTML File\n","file_out = f\"{pdf_folder}-{search_query}\"\n","go.Figure.write_html(fig,f\"{file_out}.html\") # write as html or image\n","files.download(f\"{file_out}.html\") # download your file and give me a vote my answer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"cellView":"form","id":"zl5Rpgww7WMN","executionInfo":{"status":"ok","timestamp":1675098108943,"user_tz":300,"elapsed":205,"user":{"displayName":"Malek Ibrahim","userId":"14928610410385521342"}},"outputId":"e1c40138-23d6-41f5-961c-412ce592330a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e076a535-0a12-4126-a1e8-eeef8002fd70\", \"fangzhou-xia-What exactly does Z deflection refer to in the context of AFM and LabVIEW?.html\", 3678485)"]},"metadata":{}}]}]}